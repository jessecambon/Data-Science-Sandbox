---
title: "Sentiment Analysis with R"
author: "Jesse Cambon"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  github_document:
    toc: true
---


```{r knit-settings, include=FALSE}
source(here::here("rmd_config.R"))
```

## Tidytext

Using tidytext for sentiment analysis

* https://www.tidytextmining.com/sentiment.html

```{r, warning=F, message=F}
library(janeaustenr)
library(tidyverse)
library(tidytext)
library(knitr)
library(sentimentr)

# import original dataset - one row per line of each jane austen book
austen_df <- austen_books()

# tokenize each jane austen book
tidy_books <- austen_df %>%
  group_by(book) %>%
  # add some variables
  mutate(
    linenumber = row_number(),
    chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
      ignore_case = TRUE
    )))
  ) %>%
  ungroup() %>%
  unnest_tokens(word, text)
```

Sentiment Analysis (grouping by book)

```{r}
jane_austen_sentiment <- tidy_books %>%
  inner_join(get_sentiments("afinn"))

kable(head(jane_austen_sentiment, 5))

# Summarize sentiment by book
sentiment_summ <- jane_austen_sentiment %>%
  group_by(book) %>%
  summarize(
    mean_sentiment = mean(value),
    num_sentiment_words = n()
  ) %>%
  ungroup() %>%
  arrange(desc(mean_sentiment))

kable(sentiment_summ)
```

## Sentiment Aggregation with tidytext

Make a function for quickly tokenizing a string and returning the mean sentiment

```{r}
mean_sentiment <- function(.tbl, text) {
  # Returns mean sentiment
  # Args:
  #   .tbl : tibble dataframe
  #   text (STRING) : quoted column name in .tbl of text content
  # Returns:
  #   Dataframe with mean sentiment and counts of both total words
  #   and words that had a sentiment value

  # text <- enquo(text)

  # number each row
  # use this to join text column back on later
  text_num <- .tbl %>%
    mutate(row_num = row_number())

  # tokenize the dataset (one row per token)
  tokens <- text_num %>%
    unnest_tokens(word, {{ text }}) %>%
    left_join(get_sentiments("afinn"), by = "word") %>%
    mutate(non_missing = case_when(!is.na(value) ~ 1, TRUE ~ 0)) # record if missing sentiment value

  # summarize the sentiment (value column contains sentiment of each token)
  summ <- tokens %>%
    group_by(row_num) %>%
    summarize(
      mean_sentiment = mean(value, na.rm = TRUE),
      num_words = n(),
      num_sentiment_words = sum(non_missing)
    ) %>%
    ungroup() %>%
    left_join(text_num, by = "row_num") %>%
    select(row_num, {{ text }}, everything())

  return(summ)
}
```

Note that the tidytext approach doesn't handle negation in sentiment

```{r}
test_df <- tribble(
  ~review,
  "This is the worst restaurant I have ever eaten at. It's service is abysmal.",
  "Wow, amazing food, great atmosphere. Will definitely be coming back.",
  "The restaurant was okay. Not good or bad",
  "The restaurant was okay. Not good or bad", # duplicate row
  "The stock market crashed and it was a disaster",
  "This place was not terrible.", # test negation
  "Really wasn't the best meal.", # test negation
  "Sunshine and rainbows. Everything is fantastic, couldn't be better."
)

test_sentiment <- test_df %>%
  mean_sentiment(review) %>%
  arrange(desc(mean_sentiment))

# test <- test_df %>%
#   unnest_tokens(word,review) %>%
#   left_join(get_sentiments("afinn"), by='word')

kable(test_sentiment)
```

## Sentimentr

https://github.com/trinker/sentimentr

An example of using the `sentimentr` package for sentiment analysis. This approach does handle negation.

```{r}
# Split entities into sentences, use 'element_id' column to aggregate back
# to the original entitites
sentences_df <- get_sentences(test_df)

kable(sentences_df)
# Sentiment by sentence
sentiment_df <- sentiment(sentences_df)

# Aggregate sentiment to original entities
sentiment_summ <- sentiment_by(sentences_df, by = "element_id") %>%
  bind_cols(test_df %>% select(review)) %>%
  select(element_id, review, everything()) %>%
  arrange(desc(ave_sentiment))

kable(sentiment_summ)
```
